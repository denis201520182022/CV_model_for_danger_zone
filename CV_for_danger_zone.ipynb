{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abd6bb63-c24a-40cd-93e0-85f4bd0beda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad61f0b-17c5-41bd-8aa3-aadfe425b49c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from shapely.geometry import Polygon\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f09ee5-d02d-49ae-b39c-f9af3895740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(r'D:/dataset.pkl', 'rb') as file:\n",
    "\n",
    "    dataset = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a087d1c6-357c-4a9d-9fd8-746243de753f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_path': 'D:/hackaton/data/train/cameras\\\\DpR-Csp-uipv-ShV-V1\\\\017b87c8-b17d-449e-82b7-bb03190a8f77.jpg', 'human_polygon': <POLYGON ((714 196, 843 196, 843 478, 714 478, 714 196))>, 'camera_label': 'DpR-Csp-uipv-ShV-V1'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07b50e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "annotations = []\n",
    "camera_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "720b717f-f4f2-4c56-b79d-8261be3efc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in dataset:\n",
    "    image = cv2.imread(entry['image_path'])\n",
    "    image = cv2.resize(image, (224, 224))  # Приведение изображений к одному размеру (при необходимости)\n",
    "    if entry['human_polygon'] is not None:\n",
    "        annotation = entry['human_polygon'].bounds  # Получаем прямоугольник из объекта Polygon\n",
    "    else:\n",
    "        annotation = [0,0,0,0]\n",
    "    images.append(image)\n",
    "    annotations.append(annotation)\n",
    "    camera_labels.append(entry['camera_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39cf8096",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_label_mapping = {label: idx for idx, label in enumerate(set(camera_labels))}\n",
    "camera_labels_int = np.array([camera_label_mapping[label] for label in camera_labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2db06771",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_labels_categorical = tf.keras.utils.to_categorical(camera_labels_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d71bcfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, test_images, train_annotations, test_annotations, train_camera_labels, test_camera_labels = train_test_split(\n",
    "    np.array(images), np.array(annotations), camera_labels_categorical, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaffe3d-99e7-497a-8a2c-47f5bffd6f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbf2c85f-9e39-4fb2-a862-5ec91acbd880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5735b0-6b5a-4dd9-bf94-e889370a7c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c5fe86-335d-4d26-9a92-a159d9341973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9042d6ec-cc47-400d-91f7-088ef40a42eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = layers.Input(shape=(224, 224, 3), name='conv2d_18_input')\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "output_bounding_box = layers.Dense(4, name='bounding_box')(x)\n",
    "output_camera_label = layers.Dense(len(camera_label_mapping), activation='softmax', name='camera_label')(x)\n",
    "\n",
    "model = models.Model(inputs=input_layer, outputs=[output_bounding_box, output_camera_label])\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss={'bounding_box': 'mean_squared_error', 'camera_label': 'categorical_crossentropy'},\n",
    "              metrics={'bounding_box': 'accuracy', 'camera_label': 'accuracy'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "776ddfdb-f89b-4e0f-a1e2-2c07a0595b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "135/135 [==============================] - 188s 1s/step - loss: 174381.1406 - bounding_box_loss: 174253.5938 - camera_label_loss: 127.5720 - bounding_box_accuracy: 0.5947 - camera_label_accuracy: 0.1265 - val_loss: 151140.6094 - val_bounding_box_loss: 151081.8438 - val_camera_label_loss: 58.7676 - val_bounding_box_accuracy: 0.6208 - val_camera_label_accuracy: 0.2138\n",
      "Epoch 2/10\n",
      "135/135 [==============================] - 185s 1s/step - loss: 144064.6719 - bounding_box_loss: 144021.1875 - camera_label_loss: 43.4932 - bounding_box_accuracy: 0.6254 - camera_label_accuracy: 0.3064 - val_loss: 129726.9922 - val_bounding_box_loss: 129702.6797 - val_camera_label_loss: 24.2980 - val_bounding_box_accuracy: 0.5883 - val_camera_label_accuracy: 0.3922\n",
      "Epoch 3/10\n",
      "135/135 [==============================] - 180s 1s/step - loss: 122728.5312 - bounding_box_loss: 122701.9375 - camera_label_loss: 26.6203 - bounding_box_accuracy: 0.6299 - camera_label_accuracy: 0.4346 - val_loss: 115906.7031 - val_bounding_box_loss: 115893.8672 - val_camera_label_loss: 12.8700 - val_bounding_box_accuracy: 0.6506 - val_camera_label_accuracy: 0.6812\n",
      "Epoch 4/10\n",
      "135/135 [==============================] - 182s 1s/step - loss: 110441.7891 - bounding_box_loss: 110427.7266 - camera_label_loss: 14.0663 - bounding_box_accuracy: 0.6426 - camera_label_accuracy: 0.5736 - val_loss: 112901.3047 - val_bounding_box_loss: 112889.6016 - val_camera_label_loss: 11.6998 - val_bounding_box_accuracy: 0.6255 - val_camera_label_accuracy: 0.5790\n",
      "Epoch 5/10\n",
      "135/135 [==============================] - 182s 1s/step - loss: 101436.5156 - bounding_box_loss: 101424.9688 - camera_label_loss: 11.5616 - bounding_box_accuracy: 0.6522 - camera_label_accuracy: 0.5973 - val_loss: 99278.2266 - val_bounding_box_loss: 99271.5000 - val_camera_label_loss: 6.7368 - val_bounding_box_accuracy: 0.6682 - val_camera_label_accuracy: 0.7156\n",
      "Epoch 6/10\n",
      "135/135 [==============================] - 181s 1s/step - loss: 101123.3281 - bounding_box_loss: 101115.2109 - camera_label_loss: 8.1425 - bounding_box_accuracy: 0.6519 - camera_label_accuracy: 0.6908 - val_loss: 96821.1094 - val_bounding_box_loss: 96804.2188 - val_camera_label_loss: 16.8803 - val_bounding_box_accuracy: 0.6022 - val_camera_label_accuracy: 0.5558\n",
      "Epoch 7/10\n",
      "135/135 [==============================] - 180s 1s/step - loss: 88848.1875 - bounding_box_loss: 88841.8125 - camera_label_loss: 6.3952 - bounding_box_accuracy: 0.6745 - camera_label_accuracy: 0.7368 - val_loss: 89449.0547 - val_bounding_box_loss: 89435.1250 - val_camera_label_loss: 13.9352 - val_bounding_box_accuracy: 0.6617 - val_camera_label_accuracy: 0.6459\n",
      "Epoch 8/10\n",
      "135/135 [==============================] - 179s 1s/step - loss: 85434.4609 - bounding_box_loss: 85426.3594 - camera_label_loss: 8.1182 - bounding_box_accuracy: 0.6789 - camera_label_accuracy: 0.7126 - val_loss: 99502.5391 - val_bounding_box_loss: 99496.0000 - val_camera_label_loss: 6.5263 - val_bounding_box_accuracy: 0.7017 - val_camera_label_accuracy: 0.7193\n",
      "Epoch 9/10\n",
      "135/135 [==============================] - 183s 1s/step - loss: 82539.8984 - bounding_box_loss: 82533.2734 - camera_label_loss: 6.6420 - bounding_box_accuracy: 0.6773 - camera_label_accuracy: 0.7508 - val_loss: 89173.0703 - val_bounding_box_loss: 89167.2578 - val_camera_label_loss: 5.8089 - val_bounding_box_accuracy: 0.6691 - val_camera_label_accuracy: 0.7593\n",
      "Epoch 10/10\n",
      "135/135 [==============================] - 180s 1s/step - loss: 74719.6953 - bounding_box_loss: 74713.6406 - camera_label_loss: 6.0562 - bounding_box_accuracy: 0.6915 - camera_label_accuracy: 0.7900 - val_loss: 83893.8750 - val_bounding_box_loss: 83890.0781 - val_camera_label_loss: 3.7855 - val_bounding_box_accuracy: 0.6468 - val_camera_label_accuracy: 0.8336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1be0fe11f90>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    {'conv2d_18_input': train_images},\n",
    "    {'bounding_box': train_annotations, 'camera_label': train_camera_labels},\n",
    "    epochs=10,\n",
    "    validation_data=({'conv2d_18_input': test_images},\n",
    "                     {'bounding_box': test_annotations, 'camera_label': test_camera_labels})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bfb9eb-1439-4aa4-8d17-2e4f4455fc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 8s 235ms/step - loss: 83893.8750 - bounding_box_loss: 83890.0781 - camera_label_loss: 3.7855 - bounding_box_accuracy: 0.6468 - camera_label_accuracy: 0.8336\n",
      "Loss: 83893.875\n",
      "Bounding Box Accuracy: 83890.078125\n",
      "Camera Label Accuracy: 3.7855193614959717\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = model.evaluate({'conv2d_18_input': test_images}, {'bounding_box': test_annotations, 'camera_label': test_camera_labels})\n",
    "print(\"Loss:\", results[0])\n",
    "print(\"Bounding Box Accuracy:\", results[1])\n",
    "print(\"Camera Label Accuracy:\", results[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dae6a3a-908d-4778-a8f7-1cbead4e8b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/hackaton/Work/Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/hackaton/Work/Model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('D:Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca1f280-880e-4310-802d-190ee8192a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/hackaton/Work\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/hackaton/Work\\assets\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "save_model(model, 'D:/Work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c6aa1bb-609a-4ca9-9678-010e523b44c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e716a3-dc34-4ffe-95b3-e594e12a1d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def intersect (human_vertices, danger_zone_vertices):\n",
    "    # Координаты вершин человеческой фигуры\n",
    "\n",
    "\n",
    "    \n",
    "    human_polygon = Polygon(human_vertices)\n",
    "    danger_zone_polygon = Polygon(danger_zone_vertices)\n",
    "\n",
    "    # Проверяем пересечение многоугольников\n",
    "    if human_polygon.intersects(danger_zone_polygon):\n",
    "        # Вычисляем площади многоугольников\n",
    "        human_area = human_polygon.area\n",
    "        danger_zone_area = danger_zone_polygon.area\n",
    "\n",
    "        # Вычисляем процент пересечения от площади человеческой фигуры\n",
    "        intersection_area = human_polygon.intersection(danger_zone_polygon).area\n",
    "        intersection_percentage = (intersection_area / human_area) * 100\n",
    "\n",
    "        # Проверяем условие на пересечение более чем на 15%\n",
    "        if intersection_percentage > 15:\n",
    "            print(\"Человек пересекает опасную зону на: \", intersection_percentage)\n",
    "            return true\n",
    "        else:\n",
    "            print(\"Человек пересекает опасную зону менее чем на 15%.\")\n",
    "            return false\n",
    "    else:\n",
    "        print(\"Человек не находится в опасной зоне.\")\n",
    "        return false\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc717d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "coordinats_zones = {}\n",
    "\n",
    "datapath = \"D:/hackaton/data/train/danger_zones\"\n",
    "for zone_file in os.listdir(datapath):\n",
    "    file_zone = os.path.join(datapath, zone_file)\n",
    "    \n",
    "    if zone_file.endswith(\".txt\"):\n",
    "        zone_name = os.path.splitext(zone_file)[0]\n",
    "        if os.path.exists(file_zone):\n",
    "            with open(file_zone, 'r', encoding='utf-8') as file:  \n",
    "                data = file.read()\n",
    "                \n",
    "                coordinates = [list(map(int, pair.strip('[]').split(','))) for pair in re.findall(r'\\[.*?\\]', data)]\n",
    "                name = zone_file.replace('.txt','')\n",
    "                coordinats_zones[name.replace('danger_','')] = coordinates\n",
    "\n",
    "# coordinats_zones будет содержать все координаты из всех файлов опасных зон в виде общего списка с подсписками.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d358816b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DpR-Csp-uipv-ShV-V1': [[534, 288], [834, 219], [1365, 580], [1124, 806]], 'Pgp-com2-K-1-0-9-36': [[511, 214], [776, 265], [788, 367], [445, 720], [225, 717], [195, 597], [591, 315], [468, 265]], 'Pgp-lpc2-K-0-1-38': [[181, 321], [378, 310], [379, 360], [553, 334], [544, 274], [907, 227], [996, 363], [895, 390], [881, 435], [582, 491], [570, 435], [375, 459], [371, 541], [170, 551]], 'Phl-com3-Shv2-9-K34': [[1335, 640], [1505, 662], [1491, 776], [1290, 752]], 'Php-Angc-K3-1': [[471, 717], [1434, 737], [1460, 894], [1224, 896], [1223, 761], [692, 754], [680, 916], [444, 906]], 'Php-Angc-K3-8': [[1036, 831], [480, 475], [614, 421], [1171, 691]], 'Php-Ctm-K-1-12-56': [[516, 261], [1344, 580], [452, 1078], [84, 352]], 'Php-Ctm-Shv1-2-K3': [[172, 1080], [115, 745], [441, 669], [422, 540], [864, 421], [864, 259], [1363, 151], [1881, 421], [1593, 529], [1824, 723], [1094, 1080]], 'Php-nta4-shv016309-k2-1-7': [[0, 1080], [0, 712], [192, 518], [384, 518], [825, 97], [902, 97], [1132, 367], [1132, 583], [1555, 572], [1574, 475], [1920, 475], [1920, 1080]], 'Spp-210-K1-3-3-5': [[718, 204], [1128, 340], [1128, 720], [541, 720], [345, 607]], 'Spp-210-K1-3-3-6': [[223, 345], [639, 193], [951, 477], [494, 707]], 'Spp-K1-1-2-6_zone1': [[930, 142], [1030, 320], [946, 333], [876, 157]], 'Spp-K1-1-2-6_zone2': [[395, 103], [453, 125], [271, 288], [198, 247]], 'Spp-K1-1-2-6_zone3': [[972, 434], [1080, 413], [1245, 684], [1047, 684]], 'Spp-K1-1-2-6_zone4': [[8, 398], [126, 290], [220, 341], [17, 521], [8, 458]]}\n"
     ]
    }
   ],
   "source": [
    "print(coordinats_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "27eb058e-28bf-486c-a6e3-fd089a4d66a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 97ms/step\n",
      "[[0.0000000e+00 1.6265978e-33 0.0000000e+00 5.1284850e-32 0.0000000e+00\n",
      "  2.1026236e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.4295374e-34 1.3873855e-34]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Загрузка и предобработка изображения\n",
    "image_path = 'D:/hackaton/data/train/danger_zones/Pgp-com2-K-1-0-9-36.jpg'\n",
    "T_i = cv2.imread(image_path)\n",
    "T_i = cv2.resize(T_i, (224, 224))\n",
    "T_i = np.expand_dims(T_i, axis=0)  # Добавляем размерность пакета (batch dimension)\n",
    "\n",
    "# Получение предсказаний\n",
    "predictions = model.predict({'conv2d_18_input': T_i})\n",
    "hum = predictions[0]  # Используйте индекс 0, так как это первый элемент в списке\n",
    "camera_label_predictions = predictions[1]  # Используйте индекс 1 для второго элемента\n",
    "print(camera_label_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98406a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "zone = coordinats_zones[camera_label]\n",
    "\n",
    "print(intersect(hum, zone))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755fe3cb-c5c0-4979-acf1-a945478152f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded25c16-167a-4299-902b-7a8ff26b8800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5808d739-f3ce-4663-8543-a84c9700ac39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
